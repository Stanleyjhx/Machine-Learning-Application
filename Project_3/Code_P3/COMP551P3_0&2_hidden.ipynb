{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TorxE5tnkvb2"
   },
   "outputs": [],
   "source": [
    "\n",
    "!pip install tensorflow==2.3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxkQA6oblNqI"
   },
   "source": [
    "Install TensorFlow Quantum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "saFHsRDpkvkH"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow-quantum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdgMMZEBGqyl"
   },
   "source": [
    "Now import TensorFlow and the module dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mS8YyzpOg06v"
   },
   "outputs": [],
   "source": [
    "!pip install gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "x-Vv5F0WBsd-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WcCM3Oh1Eef1"
   },
   "outputs": [],
   "source": [
    "# data normalization\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# Rescale the images from [0,255] to the [0.0,1.0] range.\n",
    "x_train, x_test = x_train[..., np.newaxis]/255.0, x_test[..., np.newaxis]/255.0\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "x_train = x_train - np.mean(x_train)\n",
    "x_test = x_test - np.mean(x_test)\n",
    "\n",
    "\n",
    "# reshape\n",
    "x_train = np.reshape(x_train, (60000, 784))\n",
    "x_test = np.reshape(x_test, (10000, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zATVIFMhBOXf"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MLP_0():\n",
    "\n",
    "  # initialization\n",
    "  def __init__(self, sizes, epochs=100, l_rate=0.001):\n",
    "      self.sizes = sizes\n",
    "      self.epochs = epochs\n",
    "      self.l_rate = l_rate\n",
    "      self.params = self.initialization()\n",
    "\n",
    "  def softmax(self, x, derivative=False):\n",
    "          exps = np.exp(x - x.max())\n",
    "          if derivative:\n",
    "              return exps / np.sum(exps, axis=0) * (1 - exps / np.sum(exps, axis=0))\n",
    "          return exps / np.sum(exps, axis=0)\n",
    "\n",
    "  def sigmoid(self, x, derivative=False):\n",
    "          if derivative:\n",
    "              return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
    "          return 1/(1 + np.exp(-x))\n",
    "\n",
    "\n",
    "  # with no hidden layer\n",
    "  def initialization(self):\n",
    "          # nums of computing units in each layer\n",
    "          input_layer=self.sizes[0]\n",
    "          output_layer=self.sizes[1]\n",
    "          params = {\n",
    "              'W0':np.random.randn(output_layer, input_layer) * np.sqrt(1. / output_layer)\n",
    "          }\n",
    "          return params\n",
    "\n",
    "  def forward(self, x_train):\n",
    "          params = self.params\n",
    "          params['A0'] = x_train\n",
    "          # direct from input layer to output layer\n",
    "          params['A1']=np.dot(params['W0'], params['A0'])\n",
    "          #softmax at the end of classification\n",
    "          # note, after I change sigmoid to softmax, the accuracy drops\n",
    "          params['S1'] =self.softmax(params['A1'])\n",
    "          return params['S1']\n",
    "\n",
    "\n",
    "  def backward(self, y_train, output):\n",
    "          params = self.params\n",
    "          changes_to_w = {}\n",
    "          # Calculate W1 update\n",
    "          error = 2 * (output - y_train) / output.shape[0]  *self.softmax(params['A1'], derivative=True)\n",
    "          changes_to_w['W0'] = np.outer(error, params['A0'])\n",
    "          return changes_to_w\n",
    "\n",
    "\n",
    "  def update_network_parameters(self, changes_to_w):        \n",
    "          for key, value in changes_to_w.items():\n",
    "              self.params[key] -= self.l_rate * value\n",
    "\n",
    "  def train(self, x_train, y_train, x_val, y_val):\n",
    "          start_time = time.time()\n",
    "          for iteration in range(self.epochs):\n",
    "              for x,y in zip(x_train, y_train):\n",
    "                  output = self.forward(x)\n",
    "                  changes_to_w = self.backward(y, output)\n",
    "                  self.update_network_parameters(changes_to_w)\n",
    "              \n",
    "              accuracy = self.evaluate_acc(x_val, y_val)\n",
    "              print('Epoch: {0}, Time Spent: {1:.2f}s, Accuracy: {2:.2f}%'.format(\n",
    "                  iteration+1, time.time() - start_time, accuracy * 100\n",
    "              ))\n",
    "  def evaluate_acc(self, x_val, y_val):\n",
    "          predictions = []\n",
    "\n",
    "          for x, y in zip(x_val, y_val):\n",
    "              output = self.forward(x)\n",
    "              pred = np.argmax(output)\n",
    "              predictions.append(pred == np.argmax(y))\n",
    "          \n",
    "          return np.mean(predictions)\n",
    "\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kh-lrT2LG8l_",
    "outputId": "a086a9e6-804f-4158-85fb-6a01e8c1c8d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Time Spent: 4.99s, Accuracy: 18.90%\n",
      "Epoch: 2, Time Spent: 10.02s, Accuracy: 30.85%\n",
      "Epoch: 3, Time Spent: 15.06s, Accuracy: 43.73%\n",
      "Epoch: 4, Time Spent: 20.22s, Accuracy: 53.18%\n",
      "Epoch: 5, Time Spent: 25.36s, Accuracy: 60.16%\n",
      "Epoch: 6, Time Spent: 30.34s, Accuracy: 65.32%\n",
      "Epoch: 7, Time Spent: 35.30s, Accuracy: 69.34%\n",
      "Epoch: 8, Time Spent: 40.22s, Accuracy: 72.47%\n",
      "Epoch: 9, Time Spent: 45.19s, Accuracy: 75.03%\n",
      "Epoch: 10, Time Spent: 50.22s, Accuracy: 76.39%\n",
      "Epoch: 11, Time Spent: 55.10s, Accuracy: 77.99%\n",
      "Epoch: 12, Time Spent: 60.05s, Accuracy: 79.33%\n",
      "Epoch: 13, Time Spent: 65.04s, Accuracy: 80.37%\n",
      "Epoch: 14, Time Spent: 70.06s, Accuracy: 81.50%\n",
      "Epoch: 15, Time Spent: 75.18s, Accuracy: 82.12%\n",
      "Epoch: 16, Time Spent: 80.18s, Accuracy: 82.60%\n",
      "Epoch: 17, Time Spent: 85.17s, Accuracy: 83.04%\n",
      "Epoch: 18, Time Spent: 90.13s, Accuracy: 83.42%\n",
      "Epoch: 19, Time Spent: 95.10s, Accuracy: 83.86%\n",
      "Epoch: 20, Time Spent: 100.05s, Accuracy: 84.33%\n",
      "Epoch: 21, Time Spent: 105.07s, Accuracy: 84.64%\n",
      "Epoch: 22, Time Spent: 110.06s, Accuracy: 84.99%\n",
      "Epoch: 23, Time Spent: 115.08s, Accuracy: 85.28%\n",
      "Epoch: 24, Time Spent: 119.98s, Accuracy: 85.47%\n",
      "Epoch: 25, Time Spent: 124.96s, Accuracy: 85.68%\n",
      "Epoch: 26, Time Spent: 129.92s, Accuracy: 85.78%\n",
      "Epoch: 27, Time Spent: 134.88s, Accuracy: 85.96%\n",
      "Epoch: 28, Time Spent: 139.82s, Accuracy: 86.18%\n",
      "Epoch: 29, Time Spent: 144.69s, Accuracy: 86.31%\n",
      "Epoch: 30, Time Spent: 149.70s, Accuracy: 86.41%\n",
      "Epoch: 31, Time Spent: 154.62s, Accuracy: 86.53%\n",
      "Epoch: 32, Time Spent: 159.68s, Accuracy: 86.77%\n",
      "Epoch: 33, Time Spent: 164.81s, Accuracy: 86.94%\n",
      "Epoch: 34, Time Spent: 169.77s, Accuracy: 87.10%\n",
      "Epoch: 35, Time Spent: 174.79s, Accuracy: 87.17%\n",
      "Epoch: 36, Time Spent: 179.76s, Accuracy: 87.22%\n",
      "Epoch: 37, Time Spent: 184.70s, Accuracy: 87.29%\n",
      "Epoch: 38, Time Spent: 189.67s, Accuracy: 87.38%\n",
      "Epoch: 39, Time Spent: 194.82s, Accuracy: 87.45%\n",
      "Epoch: 40, Time Spent: 199.84s, Accuracy: 87.63%\n",
      "Epoch: 41, Time Spent: 204.73s, Accuracy: 87.79%\n",
      "Epoch: 42, Time Spent: 209.72s, Accuracy: 87.90%\n",
      "Epoch: 43, Time Spent: 214.65s, Accuracy: 88.03%\n",
      "Epoch: 44, Time Spent: 219.56s, Accuracy: 88.11%\n",
      "Epoch: 45, Time Spent: 224.59s, Accuracy: 88.19%\n",
      "Epoch: 46, Time Spent: 229.75s, Accuracy: 88.23%\n",
      "Epoch: 47, Time Spent: 234.88s, Accuracy: 88.31%\n",
      "Epoch: 48, Time Spent: 239.86s, Accuracy: 88.44%\n",
      "Epoch: 49, Time Spent: 244.74s, Accuracy: 88.50%\n",
      "Epoch: 50, Time Spent: 249.78s, Accuracy: 88.57%\n",
      "Epoch: 51, Time Spent: 254.81s, Accuracy: 88.64%\n",
      "Epoch: 52, Time Spent: 259.72s, Accuracy: 88.64%\n",
      "Epoch: 53, Time Spent: 264.76s, Accuracy: 88.68%\n",
      "Epoch: 54, Time Spent: 269.87s, Accuracy: 88.70%\n",
      "Epoch: 55, Time Spent: 274.96s, Accuracy: 88.76%\n",
      "Epoch: 56, Time Spent: 279.94s, Accuracy: 88.78%\n",
      "Epoch: 57, Time Spent: 284.85s, Accuracy: 88.82%\n",
      "Epoch: 58, Time Spent: 289.84s, Accuracy: 88.81%\n",
      "Epoch: 59, Time Spent: 294.84s, Accuracy: 88.85%\n",
      "Epoch: 60, Time Spent: 299.90s, Accuracy: 88.93%\n",
      "Epoch: 61, Time Spent: 304.86s, Accuracy: 88.95%\n",
      "Epoch: 62, Time Spent: 309.80s, Accuracy: 89.01%\n",
      "Epoch: 63, Time Spent: 314.75s, Accuracy: 88.97%\n",
      "Epoch: 64, Time Spent: 319.71s, Accuracy: 88.99%\n",
      "Epoch: 65, Time Spent: 324.76s, Accuracy: 89.02%\n",
      "Epoch: 66, Time Spent: 329.68s, Accuracy: 89.09%\n",
      "Epoch: 67, Time Spent: 334.58s, Accuracy: 89.09%\n",
      "Epoch: 68, Time Spent: 339.65s, Accuracy: 89.15%\n",
      "Epoch: 69, Time Spent: 344.61s, Accuracy: 89.18%\n",
      "Epoch: 70, Time Spent: 349.58s, Accuracy: 89.22%\n",
      "Epoch: 71, Time Spent: 354.58s, Accuracy: 89.26%\n",
      "Epoch: 72, Time Spent: 359.72s, Accuracy: 89.30%\n",
      "Epoch: 73, Time Spent: 364.67s, Accuracy: 89.40%\n",
      "Epoch: 74, Time Spent: 369.66s, Accuracy: 89.44%\n",
      "Epoch: 75, Time Spent: 374.65s, Accuracy: 89.47%\n",
      "Epoch: 76, Time Spent: 379.61s, Accuracy: 89.48%\n",
      "Epoch: 77, Time Spent: 384.55s, Accuracy: 89.51%\n",
      "Epoch: 78, Time Spent: 389.54s, Accuracy: 89.56%\n",
      "Epoch: 79, Time Spent: 394.80s, Accuracy: 89.60%\n",
      "Epoch: 80, Time Spent: 399.75s, Accuracy: 89.63%\n",
      "Epoch: 81, Time Spent: 404.75s, Accuracy: 89.65%\n",
      "Epoch: 82, Time Spent: 409.70s, Accuracy: 89.66%\n",
      "Epoch: 83, Time Spent: 414.76s, Accuracy: 89.67%\n",
      "Epoch: 84, Time Spent: 419.72s, Accuracy: 89.69%\n",
      "Epoch: 85, Time Spent: 424.83s, Accuracy: 89.72%\n",
      "Epoch: 86, Time Spent: 429.73s, Accuracy: 89.73%\n",
      "Epoch: 87, Time Spent: 434.81s, Accuracy: 89.75%\n",
      "Epoch: 88, Time Spent: 439.95s, Accuracy: 89.79%\n",
      "Epoch: 89, Time Spent: 444.91s, Accuracy: 89.81%\n",
      "Epoch: 90, Time Spent: 449.84s, Accuracy: 89.83%\n",
      "Epoch: 91, Time Spent: 454.88s, Accuracy: 89.86%\n",
      "Epoch: 92, Time Spent: 459.82s, Accuracy: 89.88%\n",
      "Epoch: 93, Time Spent: 464.78s, Accuracy: 89.88%\n",
      "Epoch: 94, Time Spent: 469.67s, Accuracy: 89.90%\n",
      "Epoch: 95, Time Spent: 474.76s, Accuracy: 89.92%\n",
      "Epoch: 96, Time Spent: 479.88s, Accuracy: 89.96%\n",
      "Epoch: 97, Time Spent: 484.88s, Accuracy: 89.97%\n",
      "Epoch: 98, Time Spent: 489.80s, Accuracy: 89.99%\n",
      "Epoch: 99, Time Spent: 494.83s, Accuracy: 90.05%\n",
      "Epoch: 100, Time Spent: 499.77s, Accuracy: 90.08%\n"
     ]
    }
   ],
   "source": [
    "mlp0 = MLP_0(sizes=[784,10])\n",
    "mlp0.train(x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FeHnfNJao2Mv"
   },
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dJKUKcuNa92z"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MLP_2():\n",
    "\n",
    "  # initialization\n",
    "  def __init__(self, sizes, epochs=100, l_rate=0.001):\n",
    "      self.sizes = sizes\n",
    "      self.epochs = epochs\n",
    "      self.l_rate = l_rate\n",
    "      self.params = self.initialization()\n",
    "\n",
    "  def softmax(self, x, derivative=False):\n",
    "          exps = np.exp(x - x.max())\n",
    "          if derivative:\n",
    "              return exps / np.sum(exps, axis=0) * (1 - exps / np.sum(exps, axis=0))\n",
    "          return exps / np.sum(exps, axis=0)\n",
    "\n",
    "  def sigmoid(self, x, derivative=False):\n",
    "          if derivative:\n",
    "              return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
    "          return 1/(1 + np.exp(-x))\n",
    "\n",
    "  def ReLU(self, x, derivative = False):\n",
    "        if derivative:\n",
    "          y = x\n",
    "          y[y <= 0] = 0\n",
    "          y[y > 0] = 1\n",
    "          return y\n",
    "        x[x <= 0] = 0\n",
    "        return x\n",
    "\n",
    "\n",
    "  # with one hidden layer\n",
    "  def initialization(self):\n",
    "          # number of nodes in each layer\n",
    "        input_layer=self.sizes[0]\n",
    "        hidden_1=self.sizes[1]\n",
    "        hidden_2=self.sizes[2]\n",
    "        output_layer=self.sizes[3]\n",
    "\n",
    "        params = {\n",
    "            'W0':np.random.randn(hidden_1, input_layer) * np.sqrt(1. / hidden_1),\n",
    "            'W1':np.random.randn(hidden_2, hidden_1) * np.sqrt(1. / hidden_2),\n",
    "            'W2':np.random.randn(output_layer, hidden_2) * np.sqrt(1. / output_layer)\n",
    "        }\n",
    "\n",
    "        return params\n",
    "\n",
    "\n",
    "  def forward(self, x_train):\n",
    "        params = self.params\n",
    "        params['A0'] = x_train\n",
    "        # from input layer to hidden layer1\n",
    "        params['A1']=np.dot(params['W0'], params['A0'])\n",
    "        params['S1'] =self.ReLU(params['A1'])\n",
    "\n",
    "        # hidden layer1 to hidden layer2\n",
    "        params['A2'] = np.dot(params[\"W1\"], params['S1'])\n",
    "        params['S2'] = self.ReLU(params['A2'])\n",
    "\n",
    "        # hidden layer 2 to output layer\n",
    "        params['A3'] = np.dot(params[\"W2\"], params['S2'])\n",
    "        params['S3'] = self.softmax(params['A3'])\n",
    "\n",
    "        return params['S3']\n",
    "\n",
    "  def backward(self, y_train, output):\n",
    "        params = self.params\n",
    "        changes_to_w = {}\n",
    "\n",
    "        # Calculate W3 update\n",
    "        error = 2 * (output - y_train) / output.shape[0] * self.softmax(params['A3'], derivative=True)\n",
    "        changes_to_w['W2'] = np.outer(error, params['S2'])\n",
    "\n",
    "        # Calculate W1 update\n",
    "        error = np.dot(params['W2'].T, error) * self.ReLU(params['A2'],derivative=True)\n",
    "        changes_to_w['W1'] = np.outer(error, params['S1'])\n",
    "\n",
    "        # Calculate W0 update\n",
    "        error = np.dot(params['W1'].T, error) * self.ReLU(params['A1'],derivative=True)\n",
    "        changes_to_w['W0'] = np.outer(error, params['A0'])\n",
    "\n",
    "        return changes_to_w\n",
    "\n",
    "  def update_network_parameters(self, changes_to_w):        \n",
    "          for key, value in changes_to_w.items():\n",
    "              self.params[key] -= self.l_rate * value\n",
    "\n",
    "  def train(self, x_train, y_train, x_val, y_val):\n",
    "          start_time = time.time()\n",
    "          for iteration in range(self.epochs):\n",
    "              for x,y in zip(x_train, y_train):\n",
    "                  output = self.forward(x)\n",
    "                  changes_to_w = self.backward(y, output)\n",
    "                  self.update_network_parameters(changes_to_w)\n",
    "              \n",
    "              accuracy = self.evaluate_acc(x_val, y_val)\n",
    "              print('Epoch: {0}, Time Spent: {1:.2f}s, Accuracy: {2:.2f}%'.format(\n",
    "                  iteration+1, time.time() - start_time, accuracy * 100\n",
    "              ))\n",
    "  def evaluate_acc(self, x_val, y_val):\n",
    "          predictions = []\n",
    "\n",
    "          for x, y in zip(x_val, y_val):\n",
    "              output = self.forward(x)\n",
    "              pred = np.argmax(output)\n",
    "              predictions.append(pred == np.argmax(y))\n",
    "          \n",
    "          return np.mean(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9XYwPisN2zk8"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JsAHZoEhbnLr",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9701a288-3f43-4030-b174-9a07081b8d18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Time Spent: 44.85s, Accuracy: 75.01%\n",
      "Epoch: 2, Time Spent: 89.66s, Accuracy: 85.09%\n",
      "Epoch: 3, Time Spent: 134.74s, Accuracy: 88.15%\n",
      "Epoch: 4, Time Spent: 179.72s, Accuracy: 89.36%\n",
      "Epoch: 5, Time Spent: 224.66s, Accuracy: 90.13%\n",
      "Epoch: 6, Time Spent: 269.50s, Accuracy: 90.71%\n",
      "Epoch: 7, Time Spent: 314.41s, Accuracy: 91.14%\n",
      "Epoch: 8, Time Spent: 359.20s, Accuracy: 91.33%\n",
      "Epoch: 9, Time Spent: 403.93s, Accuracy: 91.62%\n",
      "Epoch: 10, Time Spent: 448.82s, Accuracy: 91.95%\n",
      "Epoch: 11, Time Spent: 493.86s, Accuracy: 92.18%\n",
      "Epoch: 12, Time Spent: 538.70s, Accuracy: 92.32%\n",
      "Epoch: 13, Time Spent: 583.67s, Accuracy: 92.64%\n",
      "Epoch: 14, Time Spent: 628.55s, Accuracy: 92.83%\n",
      "Epoch: 15, Time Spent: 673.24s, Accuracy: 92.97%\n",
      "Epoch: 16, Time Spent: 718.09s, Accuracy: 93.09%\n",
      "Epoch: 17, Time Spent: 762.87s, Accuracy: 93.24%\n",
      "Epoch: 18, Time Spent: 807.60s, Accuracy: 93.38%\n",
      "Epoch: 19, Time Spent: 852.41s, Accuracy: 93.47%\n",
      "Epoch: 20, Time Spent: 897.19s, Accuracy: 93.55%\n",
      "Epoch: 21, Time Spent: 942.19s, Accuracy: 93.65%\n",
      "Epoch: 22, Time Spent: 986.88s, Accuracy: 93.73%\n",
      "Epoch: 23, Time Spent: 1031.71s, Accuracy: 93.78%\n",
      "Epoch: 24, Time Spent: 1076.35s, Accuracy: 93.87%\n",
      "Epoch: 25, Time Spent: 1121.12s, Accuracy: 93.92%\n",
      "Epoch: 26, Time Spent: 1166.01s, Accuracy: 94.02%\n",
      "Epoch: 27, Time Spent: 1211.05s, Accuracy: 94.13%\n",
      "Epoch: 28, Time Spent: 1256.18s, Accuracy: 94.13%\n",
      "Epoch: 29, Time Spent: 1301.48s, Accuracy: 94.18%\n",
      "Epoch: 30, Time Spent: 1346.52s, Accuracy: 94.21%\n",
      "Epoch: 31, Time Spent: 1391.36s, Accuracy: 94.26%\n",
      "Epoch: 32, Time Spent: 1436.14s, Accuracy: 94.33%\n",
      "Epoch: 33, Time Spent: 1480.99s, Accuracy: 94.40%\n",
      "Epoch: 34, Time Spent: 1525.75s, Accuracy: 94.43%\n",
      "Epoch: 35, Time Spent: 1570.52s, Accuracy: 94.51%\n",
      "Epoch: 36, Time Spent: 1615.27s, Accuracy: 94.56%\n",
      "Epoch: 37, Time Spent: 1660.11s, Accuracy: 94.58%\n",
      "Epoch: 38, Time Spent: 1704.86s, Accuracy: 94.62%\n",
      "Epoch: 39, Time Spent: 1749.72s, Accuracy: 94.64%\n",
      "Epoch: 40, Time Spent: 1794.45s, Accuracy: 94.72%\n",
      "Epoch: 41, Time Spent: 1839.31s, Accuracy: 94.77%\n",
      "Epoch: 42, Time Spent: 1884.17s, Accuracy: 94.80%\n",
      "Epoch: 43, Time Spent: 1929.08s, Accuracy: 94.82%\n",
      "Epoch: 44, Time Spent: 1973.94s, Accuracy: 94.83%\n",
      "Epoch: 45, Time Spent: 2018.73s, Accuracy: 94.85%\n",
      "Epoch: 46, Time Spent: 2063.43s, Accuracy: 94.86%\n",
      "Epoch: 47, Time Spent: 2108.23s, Accuracy: 94.87%\n",
      "Epoch: 48, Time Spent: 2153.05s, Accuracy: 94.91%\n",
      "Epoch: 49, Time Spent: 2197.82s, Accuracy: 94.93%\n",
      "Epoch: 50, Time Spent: 2242.63s, Accuracy: 94.99%\n",
      "Epoch: 51, Time Spent: 2287.52s, Accuracy: 95.02%\n",
      "Epoch: 52, Time Spent: 2332.39s, Accuracy: 95.01%\n",
      "Epoch: 53, Time Spent: 2377.27s, Accuracy: 95.03%\n",
      "Epoch: 54, Time Spent: 2422.13s, Accuracy: 95.15%\n",
      "Epoch: 55, Time Spent: 2466.77s, Accuracy: 95.16%\n",
      "Epoch: 56, Time Spent: 2511.34s, Accuracy: 95.15%\n",
      "Epoch: 57, Time Spent: 2555.89s, Accuracy: 95.18%\n",
      "Epoch: 58, Time Spent: 2600.47s, Accuracy: 95.16%\n",
      "Epoch: 59, Time Spent: 2645.16s, Accuracy: 95.18%\n",
      "Epoch: 60, Time Spent: 2689.70s, Accuracy: 95.19%\n",
      "Epoch: 61, Time Spent: 2734.01s, Accuracy: 95.23%\n",
      "Epoch: 62, Time Spent: 2778.46s, Accuracy: 95.26%\n",
      "Epoch: 63, Time Spent: 2822.76s, Accuracy: 95.25%\n",
      "Epoch: 64, Time Spent: 2867.78s, Accuracy: 95.26%\n",
      "Epoch: 65, Time Spent: 2915.20s, Accuracy: 95.32%\n",
      "Epoch: 66, Time Spent: 2962.66s, Accuracy: 95.32%\n",
      "Epoch: 67, Time Spent: 3010.24s, Accuracy: 95.31%\n",
      "Epoch: 68, Time Spent: 3057.76s, Accuracy: 95.31%\n",
      "Epoch: 69, Time Spent: 3105.31s, Accuracy: 95.30%\n",
      "Epoch: 70, Time Spent: 3152.84s, Accuracy: 95.32%\n",
      "Epoch: 71, Time Spent: 3200.59s, Accuracy: 95.37%\n",
      "Epoch: 72, Time Spent: 3248.28s, Accuracy: 95.39%\n",
      "Epoch: 73, Time Spent: 3295.98s, Accuracy: 95.41%\n",
      "Epoch: 74, Time Spent: 3343.89s, Accuracy: 95.46%\n",
      "Epoch: 75, Time Spent: 3391.51s, Accuracy: 95.48%\n",
      "Epoch: 76, Time Spent: 3439.22s, Accuracy: 95.49%\n",
      "Epoch: 77, Time Spent: 3486.89s, Accuracy: 95.54%\n",
      "Epoch: 78, Time Spent: 3534.65s, Accuracy: 95.55%\n",
      "Epoch: 79, Time Spent: 3582.44s, Accuracy: 95.55%\n",
      "Epoch: 80, Time Spent: 3630.16s, Accuracy: 95.57%\n",
      "Epoch: 81, Time Spent: 3678.02s, Accuracy: 95.56%\n",
      "Epoch: 82, Time Spent: 3725.84s, Accuracy: 95.58%\n",
      "Epoch: 83, Time Spent: 3773.62s, Accuracy: 95.61%\n",
      "Epoch: 84, Time Spent: 3821.30s, Accuracy: 95.61%\n",
      "Epoch: 85, Time Spent: 3869.15s, Accuracy: 95.62%\n",
      "Epoch: 86, Time Spent: 3917.01s, Accuracy: 95.65%\n",
      "Epoch: 87, Time Spent: 3965.05s, Accuracy: 95.67%\n",
      "Epoch: 88, Time Spent: 4012.53s, Accuracy: 95.66%\n",
      "Epoch: 89, Time Spent: 4059.95s, Accuracy: 95.69%\n",
      "Epoch: 90, Time Spent: 4107.51s, Accuracy: 95.67%\n",
      "Epoch: 91, Time Spent: 4155.19s, Accuracy: 95.63%\n",
      "Epoch: 92, Time Spent: 4202.82s, Accuracy: 95.62%\n",
      "Epoch: 93, Time Spent: 4250.35s, Accuracy: 95.60%\n",
      "Epoch: 94, Time Spent: 4297.96s, Accuracy: 95.60%\n",
      "Epoch: 95, Time Spent: 4345.46s, Accuracy: 95.60%\n",
      "Epoch: 96, Time Spent: 4393.02s, Accuracy: 95.61%\n",
      "Epoch: 97, Time Spent: 4440.80s, Accuracy: 95.62%\n",
      "Epoch: 98, Time Spent: 4488.39s, Accuracy: 95.63%\n",
      "Epoch: 99, Time Spent: 4535.99s, Accuracy: 95.65%\n"
     ]
    }
   ],
   "source": [
    "mlp2 = MLP_2(sizes=[784,128,128,10])\n",
    "mlp2.train(x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NWKp-bOP2FPP"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MLP_2_sigmoid():\n",
    "\n",
    "  # initialization\n",
    "  def __init__(self, sizes, epochs=300, l_rate=0.001):\n",
    "      self.sizes = sizes\n",
    "      self.epochs = epochs\n",
    "      self.l_rate = l_rate\n",
    "      self.params = self.initialization()\n",
    "\n",
    "  def softmax(self, x, derivative=False):\n",
    "          exps = np.exp(x - x.max())\n",
    "          if derivative:\n",
    "              return exps / np.sum(exps, axis=0) * (1 - exps / np.sum(exps, axis=0))\n",
    "          return exps / np.sum(exps, axis=0)\n",
    "\n",
    "  def sigmoid(self, x, derivative=False):\n",
    "          if derivative:\n",
    "              return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
    "          return 1/(1 + np.exp(-x))\n",
    "\n",
    "  def ReLU(self, x, derivative = False):\n",
    "        if derivative:\n",
    "          y = x\n",
    "          y[y <= 0] = 0\n",
    "          y[y > 0] = 1\n",
    "          return y\n",
    "        x[x <= 0] = 0\n",
    "        return x\n",
    "\n",
    "\n",
    "  # with one hidden layer\n",
    "  def initialization(self):\n",
    "          # number of nodes in each layer\n",
    "        input_layer=self.sizes[0]\n",
    "        hidden_1=self.sizes[1]\n",
    "        hidden_2=self.sizes[2]\n",
    "        output_layer=self.sizes[3]\n",
    "\n",
    "        params = {\n",
    "            'W0':np.random.randn(hidden_1, input_layer) * np.sqrt(1. / hidden_1),\n",
    "            'W1':np.random.randn(hidden_2, hidden_1) * np.sqrt(1. / hidden_2),\n",
    "            'W2':np.random.randn(output_layer, hidden_2) * np.sqrt(1. / output_layer)\n",
    "        }\n",
    "\n",
    "        return params\n",
    "\n",
    "\n",
    "  def forward(self, x_train):\n",
    "        params = self.params\n",
    "        params['A0'] = x_train\n",
    "        # from input layer to hidden layer1\n",
    "        params['A1']=np.dot(params['W0'], params['A0'])\n",
    "        params['S1'] =self.sigmoid(params['A1'])\n",
    "\n",
    "        # hidden layer1 to hidden layer2\n",
    "        params['A2'] = np.dot(params[\"W1\"], params['S1'])\n",
    "        params['S2'] = self.sigmoid(params['A2'])\n",
    "\n",
    "        # hidden layer 2 to output layer\n",
    "        params['A3'] = np.dot(params[\"W2\"], params['S2'])\n",
    "        params['S3'] = self.softmax(params['A3'])\n",
    "\n",
    "        return params['S3']\n",
    "\n",
    "  def backward(self, y_train, output):\n",
    "        params = self.params\n",
    "        changes_to_w = {}\n",
    "\n",
    "        # Calculate W3 update\n",
    "        error = 2 * (output - y_train) / output.shape[0] * self.softmax(params['A3'], derivative=True)\n",
    "        changes_to_w['W2'] = np.outer(error, params['S2'])\n",
    "\n",
    "        # Calculate W1 update\n",
    "        error = np.dot(params['W2'].T, error) * self.sigmoid(params['A2'],derivative=True)\n",
    "        changes_to_w['W1'] = np.outer(error, params['S1'])\n",
    "\n",
    "        # Calculate W0 update\n",
    "        error = np.dot(params['W1'].T, error) * self.sigmoid(params['A1'],derivative=True)\n",
    "        changes_to_w['W0'] = np.outer(error, params['A0'])\n",
    "\n",
    "        return changes_to_w\n",
    "\n",
    "  def update_network_parameters(self, changes_to_w):        \n",
    "          for key, value in changes_to_w.items():\n",
    "              self.params[key] -= self.l_rate * value\n",
    "\n",
    "  def train(self, x_train, y_train, x_val, y_val):\n",
    "          start_time = time.time()\n",
    "          for iteration in range(self.epochs):\n",
    "              for x,y in zip(x_train, y_train):\n",
    "                  output = self.forward(x)\n",
    "                  changes_to_w = self.backward(y, output)\n",
    "                  self.update_network_parameters(changes_to_w)\n",
    "              \n",
    "              accuracy = self.evaluate_acc(x_val, y_val)\n",
    "              print('Epoch: {0}, Time Spent: {1:.2f}s, Accuracy: {2:.2f}%'.format(\n",
    "                  iteration+1, time.time() - start_time, accuracy * 100\n",
    "              ))\n",
    "  def evaluate_acc(self, x_val, y_val):\n",
    "          predictions = []\n",
    "\n",
    "          for x, y in zip(x_val, y_val):\n",
    "              output = self.forward(x)\n",
    "              pred = np.argmax(output)\n",
    "              predictions.append(pred == np.argmax(y))\n",
    "          \n",
    "          return np.mean(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jd7LxOwP3ELe",
    "outputId": "be4edadf-be0d-4b14-e389-d30554a422d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Time Spent: 59.98s, Accuracy: 37.68%\n",
      "Epoch: 2, Time Spent: 119.80s, Accuracy: 41.51%\n",
      "Epoch: 3, Time Spent: 180.49s, Accuracy: 43.21%\n",
      "Epoch: 4, Time Spent: 239.86s, Accuracy: 46.96%\n",
      "Epoch: 5, Time Spent: 300.06s, Accuracy: 52.60%\n",
      "Epoch: 6, Time Spent: 361.43s, Accuracy: 57.64%\n",
      "Epoch: 7, Time Spent: 421.95s, Accuracy: 60.65%\n",
      "Epoch: 8, Time Spent: 481.74s, Accuracy: 62.12%\n",
      "Epoch: 9, Time Spent: 541.65s, Accuracy: 63.35%\n",
      "Epoch: 10, Time Spent: 601.75s, Accuracy: 64.55%\n",
      "Epoch: 11, Time Spent: 661.62s, Accuracy: 65.79%\n",
      "Epoch: 12, Time Spent: 721.47s, Accuracy: 67.08%\n",
      "Epoch: 13, Time Spent: 781.41s, Accuracy: 67.83%\n",
      "Epoch: 14, Time Spent: 841.09s, Accuracy: 68.42%\n",
      "Epoch: 15, Time Spent: 901.08s, Accuracy: 68.83%\n",
      "Epoch: 16, Time Spent: 961.81s, Accuracy: 68.97%\n",
      "Epoch: 17, Time Spent: 1022.42s, Accuracy: 69.10%\n",
      "Epoch: 18, Time Spent: 1084.08s, Accuracy: 69.38%\n",
      "Epoch: 19, Time Spent: 1146.12s, Accuracy: 69.77%\n",
      "Epoch: 20, Time Spent: 1206.87s, Accuracy: 70.17%\n",
      "Epoch: 21, Time Spent: 1266.79s, Accuracy: 70.67%\n",
      "Epoch: 22, Time Spent: 1326.22s, Accuracy: 71.23%\n",
      "Epoch: 23, Time Spent: 1384.68s, Accuracy: 71.71%\n",
      "Epoch: 24, Time Spent: 1442.48s, Accuracy: 72.15%\n",
      "Epoch: 25, Time Spent: 1500.43s, Accuracy: 72.54%\n",
      "Epoch: 26, Time Spent: 1558.55s, Accuracy: 72.94%\n",
      "Epoch: 27, Time Spent: 1617.30s, Accuracy: 73.44%\n",
      "Epoch: 28, Time Spent: 1675.57s, Accuracy: 73.88%\n",
      "Epoch: 29, Time Spent: 1735.47s, Accuracy: 74.33%\n",
      "Epoch: 30, Time Spent: 1793.74s, Accuracy: 74.78%\n",
      "Epoch: 31, Time Spent: 1855.68s, Accuracy: 75.04%\n",
      "Epoch: 32, Time Spent: 1913.79s, Accuracy: 75.39%\n",
      "Epoch: 33, Time Spent: 1973.75s, Accuracy: 75.71%\n",
      "Epoch: 34, Time Spent: 2035.00s, Accuracy: 76.05%\n",
      "Epoch: 35, Time Spent: 2095.29s, Accuracy: 76.28%\n",
      "Epoch: 36, Time Spent: 2155.75s, Accuracy: 76.50%\n",
      "Epoch: 37, Time Spent: 2215.90s, Accuracy: 76.83%\n",
      "Epoch: 38, Time Spent: 2277.63s, Accuracy: 77.02%\n",
      "Epoch: 39, Time Spent: 2339.68s, Accuracy: 77.22%\n",
      "Epoch: 40, Time Spent: 2401.01s, Accuracy: 77.46%\n",
      "Epoch: 41, Time Spent: 2462.42s, Accuracy: 77.61%\n",
      "Epoch: 42, Time Spent: 2523.09s, Accuracy: 77.96%\n",
      "Epoch: 43, Time Spent: 2583.94s, Accuracy: 78.34%\n",
      "Epoch: 44, Time Spent: 2644.49s, Accuracy: 78.73%\n",
      "Epoch: 45, Time Spent: 2705.32s, Accuracy: 79.10%\n",
      "Epoch: 46, Time Spent: 2764.98s, Accuracy: 79.31%\n",
      "Epoch: 47, Time Spent: 2825.11s, Accuracy: 79.49%\n",
      "Epoch: 48, Time Spent: 2889.00s, Accuracy: 79.67%\n",
      "Epoch: 49, Time Spent: 2949.07s, Accuracy: 79.71%\n",
      "Epoch: 50, Time Spent: 3009.23s, Accuracy: 79.81%\n",
      "Epoch: 51, Time Spent: 3069.41s, Accuracy: 79.80%\n",
      "Epoch: 52, Time Spent: 3130.14s, Accuracy: 79.81%\n",
      "Epoch: 53, Time Spent: 3194.43s, Accuracy: 79.92%\n",
      "Epoch: 54, Time Spent: 3255.37s, Accuracy: 79.96%\n",
      "Epoch: 55, Time Spent: 3317.63s, Accuracy: 80.04%\n",
      "Epoch: 56, Time Spent: 3378.16s, Accuracy: 80.11%\n",
      "Epoch: 57, Time Spent: 3438.54s, Accuracy: 80.17%\n",
      "Epoch: 58, Time Spent: 3498.78s, Accuracy: 80.26%\n",
      "Epoch: 59, Time Spent: 3559.34s, Accuracy: 80.33%\n",
      "Epoch: 60, Time Spent: 3620.32s, Accuracy: 80.38%\n",
      "Epoch: 61, Time Spent: 3681.51s, Accuracy: 80.43%\n",
      "Epoch: 62, Time Spent: 3741.92s, Accuracy: 80.52%\n",
      "Epoch: 63, Time Spent: 3801.61s, Accuracy: 80.59%\n",
      "Epoch: 64, Time Spent: 3862.01s, Accuracy: 80.60%\n",
      "Epoch: 65, Time Spent: 3922.40s, Accuracy: 80.61%\n",
      "Epoch: 66, Time Spent: 3984.24s, Accuracy: 80.66%\n",
      "Epoch: 67, Time Spent: 4046.17s, Accuracy: 80.69%\n",
      "Epoch: 68, Time Spent: 4109.62s, Accuracy: 80.76%\n",
      "Epoch: 69, Time Spent: 4174.38s, Accuracy: 80.84%\n",
      "Epoch: 70, Time Spent: 4239.47s, Accuracy: 80.92%\n",
      "Epoch: 71, Time Spent: 4304.76s, Accuracy: 80.95%\n",
      "Epoch: 72, Time Spent: 4371.70s, Accuracy: 81.05%\n",
      "Epoch: 73, Time Spent: 4436.82s, Accuracy: 81.12%\n",
      "Epoch: 74, Time Spent: 4502.55s, Accuracy: 81.18%\n",
      "Epoch: 75, Time Spent: 4568.26s, Accuracy: 81.19%\n",
      "Epoch: 76, Time Spent: 4637.23s, Accuracy: 81.18%\n",
      "Epoch: 77, Time Spent: 4704.16s, Accuracy: 81.19%\n",
      "Epoch: 78, Time Spent: 4769.91s, Accuracy: 81.27%\n",
      "Epoch: 79, Time Spent: 4835.88s, Accuracy: 81.33%\n",
      "Epoch: 80, Time Spent: 4902.09s, Accuracy: 81.36%\n",
      "Epoch: 81, Time Spent: 4966.93s, Accuracy: 81.41%\n",
      "Epoch: 82, Time Spent: 5030.88s, Accuracy: 81.42%\n",
      "Epoch: 83, Time Spent: 5094.50s, Accuracy: 81.46%\n",
      "Epoch: 84, Time Spent: 5158.82s, Accuracy: 81.51%\n",
      "Epoch: 85, Time Spent: 5223.12s, Accuracy: 81.59%\n",
      "Epoch: 86, Time Spent: 5285.17s, Accuracy: 81.59%\n",
      "Epoch: 87, Time Spent: 5346.65s, Accuracy: 81.65%\n",
      "Epoch: 88, Time Spent: 5407.26s, Accuracy: 81.66%\n",
      "Epoch: 89, Time Spent: 5469.14s, Accuracy: 81.70%\n",
      "Epoch: 90, Time Spent: 5531.00s, Accuracy: 81.75%\n",
      "Epoch: 91, Time Spent: 5593.65s, Accuracy: 81.79%\n",
      "Epoch: 92, Time Spent: 5655.32s, Accuracy: 81.86%\n",
      "Epoch: 93, Time Spent: 5717.31s, Accuracy: 82.02%\n",
      "Epoch: 94, Time Spent: 5780.65s, Accuracy: 82.61%\n",
      "Epoch: 95, Time Spent: 5843.22s, Accuracy: 83.30%\n",
      "Epoch: 96, Time Spent: 5906.68s, Accuracy: 83.99%\n",
      "Epoch: 97, Time Spent: 5969.06s, Accuracy: 84.80%\n",
      "Epoch: 98, Time Spent: 6031.48s, Accuracy: 85.43%\n",
      "Epoch: 99, Time Spent: 6094.07s, Accuracy: 86.07%\n",
      "Epoch: 100, Time Spent: 6156.29s, Accuracy: 86.62%\n",
      "Epoch: 101, Time Spent: 6218.59s, Accuracy: 87.10%\n",
      "Epoch: 102, Time Spent: 6280.76s, Accuracy: 87.53%\n",
      "Epoch: 103, Time Spent: 6343.25s, Accuracy: 87.92%\n",
      "Epoch: 104, Time Spent: 6404.35s, Accuracy: 88.30%\n",
      "Epoch: 105, Time Spent: 6466.33s, Accuracy: 88.57%\n",
      "Epoch: 106, Time Spent: 6527.34s, Accuracy: 88.79%\n",
      "Epoch: 107, Time Spent: 6588.61s, Accuracy: 88.91%\n",
      "Epoch: 108, Time Spent: 6649.53s, Accuracy: 89.05%\n",
      "Epoch: 109, Time Spent: 6711.90s, Accuracy: 89.15%\n",
      "Epoch: 110, Time Spent: 6773.00s, Accuracy: 89.30%\n",
      "Epoch: 111, Time Spent: 6832.72s, Accuracy: 89.43%\n",
      "Epoch: 112, Time Spent: 6894.67s, Accuracy: 89.52%\n",
      "Epoch: 113, Time Spent: 6954.52s, Accuracy: 89.59%\n",
      "Epoch: 114, Time Spent: 7015.27s, Accuracy: 89.73%\n",
      "Epoch: 115, Time Spent: 7076.03s, Accuracy: 89.85%\n",
      "Epoch: 116, Time Spent: 7137.01s, Accuracy: 89.94%\n",
      "Epoch: 117, Time Spent: 7198.10s, Accuracy: 90.01%\n",
      "Epoch: 118, Time Spent: 7259.28s, Accuracy: 90.05%\n",
      "Epoch: 119, Time Spent: 7320.04s, Accuracy: 90.14%\n",
      "Epoch: 120, Time Spent: 7381.17s, Accuracy: 90.25%\n",
      "Epoch: 121, Time Spent: 7440.77s, Accuracy: 90.31%\n",
      "Epoch: 122, Time Spent: 7500.88s, Accuracy: 90.36%\n",
      "Epoch: 123, Time Spent: 7560.99s, Accuracy: 90.42%\n",
      "Epoch: 124, Time Spent: 7621.35s, Accuracy: 90.49%\n",
      "Epoch: 125, Time Spent: 7681.17s, Accuracy: 90.54%\n",
      "Epoch: 126, Time Spent: 7740.46s, Accuracy: 90.57%\n",
      "Epoch: 127, Time Spent: 7799.29s, Accuracy: 90.61%\n",
      "Epoch: 128, Time Spent: 7859.20s, Accuracy: 90.65%\n",
      "Epoch: 129, Time Spent: 7917.55s, Accuracy: 90.69%\n",
      "Epoch: 130, Time Spent: 7976.58s, Accuracy: 90.74%\n",
      "Epoch: 131, Time Spent: 8034.79s, Accuracy: 90.78%\n",
      "Epoch: 132, Time Spent: 8092.91s, Accuracy: 90.77%\n",
      "Epoch: 133, Time Spent: 8150.81s, Accuracy: 90.86%\n",
      "Epoch: 134, Time Spent: 8209.57s, Accuracy: 90.90%\n",
      "Epoch: 135, Time Spent: 8269.01s, Accuracy: 90.90%\n",
      "Epoch: 136, Time Spent: 8328.05s, Accuracy: 90.93%\n",
      "Epoch: 137, Time Spent: 8386.79s, Accuracy: 90.94%\n",
      "Epoch: 138, Time Spent: 8446.21s, Accuracy: 90.94%\n",
      "Epoch: 139, Time Spent: 8505.24s, Accuracy: 90.96%\n",
      "Epoch: 140, Time Spent: 8564.33s, Accuracy: 90.96%\n",
      "Epoch: 141, Time Spent: 8622.74s, Accuracy: 90.99%\n",
      "Epoch: 142, Time Spent: 8682.28s, Accuracy: 91.00%\n",
      "Epoch: 143, Time Spent: 8741.50s, Accuracy: 91.03%\n",
      "Epoch: 144, Time Spent: 8800.07s, Accuracy: 91.09%\n",
      "Epoch: 145, Time Spent: 8860.11s, Accuracy: 91.15%\n",
      "Epoch: 146, Time Spent: 8922.07s, Accuracy: 91.18%\n",
      "Epoch: 147, Time Spent: 8981.29s, Accuracy: 91.18%\n",
      "Epoch: 148, Time Spent: 9040.52s, Accuracy: 91.18%\n",
      "Epoch: 149, Time Spent: 9099.34s, Accuracy: 91.19%\n",
      "Epoch: 150, Time Spent: 9159.53s, Accuracy: 91.21%\n",
      "Epoch: 151, Time Spent: 9218.76s, Accuracy: 91.22%\n",
      "Epoch: 152, Time Spent: 9277.32s, Accuracy: 91.24%\n",
      "Epoch: 153, Time Spent: 9336.87s, Accuracy: 91.25%\n",
      "Epoch: 154, Time Spent: 9395.57s, Accuracy: 91.27%\n",
      "Epoch: 155, Time Spent: 9455.91s, Accuracy: 91.32%\n",
      "Epoch: 156, Time Spent: 9516.14s, Accuracy: 91.35%\n",
      "Epoch: 157, Time Spent: 9575.48s, Accuracy: 91.36%\n",
      "Epoch: 158, Time Spent: 9634.94s, Accuracy: 91.32%\n",
      "Epoch: 159, Time Spent: 9693.85s, Accuracy: 91.33%\n",
      "Epoch: 160, Time Spent: 9753.19s, Accuracy: 91.38%\n",
      "Epoch: 161, Time Spent: 9813.09s, Accuracy: 91.42%\n",
      "Epoch: 162, Time Spent: 9872.21s, Accuracy: 91.44%\n",
      "Epoch: 163, Time Spent: 9931.27s, Accuracy: 91.46%\n",
      "Epoch: 164, Time Spent: 9990.15s, Accuracy: 91.48%\n",
      "Epoch: 165, Time Spent: 10049.22s, Accuracy: 91.51%\n",
      "Epoch: 166, Time Spent: 10109.23s, Accuracy: 91.55%\n",
      "Epoch: 167, Time Spent: 10168.18s, Accuracy: 91.55%\n",
      "Epoch: 168, Time Spent: 10226.67s, Accuracy: 91.57%\n",
      "Epoch: 169, Time Spent: 10285.37s, Accuracy: 91.58%\n",
      "Epoch: 170, Time Spent: 10344.98s, Accuracy: 91.61%\n",
      "Epoch: 171, Time Spent: 10406.15s, Accuracy: 91.64%\n",
      "Epoch: 172, Time Spent: 10465.93s, Accuracy: 91.66%\n",
      "Epoch: 173, Time Spent: 10525.08s, Accuracy: 91.69%\n",
      "Epoch: 174, Time Spent: 10584.18s, Accuracy: 91.73%\n",
      "Epoch: 175, Time Spent: 10643.64s, Accuracy: 91.79%\n",
      "Epoch: 176, Time Spent: 10704.28s, Accuracy: 91.82%\n",
      "Epoch: 177, Time Spent: 10765.81s, Accuracy: 91.81%\n",
      "Epoch: 178, Time Spent: 10826.13s, Accuracy: 91.82%\n",
      "Epoch: 179, Time Spent: 10885.83s, Accuracy: 91.81%\n",
      "Epoch: 180, Time Spent: 10947.00s, Accuracy: 91.82%\n",
      "Epoch: 181, Time Spent: 11007.62s, Accuracy: 91.84%\n",
      "Epoch: 182, Time Spent: 11067.27s, Accuracy: 91.85%\n",
      "Epoch: 183, Time Spent: 11127.73s, Accuracy: 91.88%\n",
      "Epoch: 184, Time Spent: 11187.65s, Accuracy: 91.90%\n",
      "Epoch: 185, Time Spent: 11247.25s, Accuracy: 91.90%\n",
      "Epoch: 186, Time Spent: 11306.88s, Accuracy: 91.90%\n",
      "Epoch: 187, Time Spent: 11366.38s, Accuracy: 91.94%\n",
      "Epoch: 188, Time Spent: 11426.60s, Accuracy: 91.96%\n",
      "Epoch: 189, Time Spent: 11485.48s, Accuracy: 91.99%\n",
      "Epoch: 190, Time Spent: 11544.69s, Accuracy: 92.02%\n",
      "Epoch: 191, Time Spent: 11603.73s, Accuracy: 92.04%\n",
      "Epoch: 192, Time Spent: 11662.95s, Accuracy: 92.06%\n",
      "Epoch: 193, Time Spent: 11722.10s, Accuracy: 92.06%\n",
      "Epoch: 194, Time Spent: 11781.74s, Accuracy: 92.06%\n",
      "Epoch: 195, Time Spent: 11841.19s, Accuracy: 92.11%\n",
      "Epoch: 196, Time Spent: 11901.29s, Accuracy: 92.11%\n",
      "Epoch: 197, Time Spent: 11960.84s, Accuracy: 92.12%\n",
      "Epoch: 198, Time Spent: 12020.14s, Accuracy: 92.15%\n",
      "Epoch: 199, Time Spent: 12080.45s, Accuracy: 92.15%\n",
      "Epoch: 200, Time Spent: 12139.61s, Accuracy: 92.15%\n",
      "Epoch: 201, Time Spent: 12199.00s, Accuracy: 92.17%\n",
      "Epoch: 202, Time Spent: 12261.65s, Accuracy: 92.21%\n",
      "Epoch: 203, Time Spent: 12323.58s, Accuracy: 92.23%\n",
      "Epoch: 204, Time Spent: 12385.93s, Accuracy: 92.27%\n",
      "Epoch: 205, Time Spent: 12446.35s, Accuracy: 92.26%\n",
      "Epoch: 206, Time Spent: 12506.26s, Accuracy: 92.26%\n",
      "Epoch: 207, Time Spent: 12565.57s, Accuracy: 92.30%\n",
      "Epoch: 208, Time Spent: 12625.44s, Accuracy: 92.30%\n",
      "Epoch: 209, Time Spent: 12685.21s, Accuracy: 92.31%\n",
      "Epoch: 210, Time Spent: 12745.55s, Accuracy: 92.33%\n",
      "Epoch: 211, Time Spent: 12804.26s, Accuracy: 92.34%\n",
      "Epoch: 212, Time Spent: 12863.95s, Accuracy: 92.33%\n",
      "Epoch: 213, Time Spent: 12923.54s, Accuracy: 92.34%\n",
      "Epoch: 214, Time Spent: 12983.10s, Accuracy: 92.37%\n",
      "Epoch: 215, Time Spent: 13042.60s, Accuracy: 92.37%\n",
      "Epoch: 216, Time Spent: 13102.59s, Accuracy: 92.37%\n",
      "Epoch: 217, Time Spent: 13161.21s, Accuracy: 92.39%\n",
      "Epoch: 218, Time Spent: 13220.08s, Accuracy: 92.42%\n",
      "Epoch: 219, Time Spent: 13279.07s, Accuracy: 92.43%\n",
      "Epoch: 220, Time Spent: 13338.44s, Accuracy: 92.46%\n",
      "Epoch: 221, Time Spent: 13397.78s, Accuracy: 92.49%\n",
      "Epoch: 222, Time Spent: 13457.48s, Accuracy: 92.51%\n",
      "Epoch: 223, Time Spent: 13516.54s, Accuracy: 92.50%\n",
      "Epoch: 224, Time Spent: 13575.32s, Accuracy: 92.50%\n",
      "Epoch: 225, Time Spent: 13634.03s, Accuracy: 92.54%\n",
      "Epoch: 226, Time Spent: 13693.67s, Accuracy: 92.54%\n",
      "Epoch: 227, Time Spent: 13751.86s, Accuracy: 92.54%\n",
      "Epoch: 228, Time Spent: 13810.13s, Accuracy: 92.56%\n",
      "Epoch: 229, Time Spent: 13868.87s, Accuracy: 92.57%\n",
      "Epoch: 230, Time Spent: 13927.68s, Accuracy: 92.58%\n",
      "Epoch: 231, Time Spent: 13986.42s, Accuracy: 92.58%\n",
      "Epoch: 232, Time Spent: 14045.95s, Accuracy: 92.59%\n",
      "Epoch: 233, Time Spent: 14105.35s, Accuracy: 92.60%\n",
      "Epoch: 234, Time Spent: 14164.53s, Accuracy: 92.62%\n",
      "Epoch: 235, Time Spent: 14224.66s, Accuracy: 92.63%\n",
      "Epoch: 236, Time Spent: 14283.93s, Accuracy: 92.65%\n",
      "Epoch: 237, Time Spent: 14343.64s, Accuracy: 92.65%\n",
      "Epoch: 238, Time Spent: 14402.62s, Accuracy: 92.65%\n",
      "Epoch: 239, Time Spent: 14461.58s, Accuracy: 92.67%\n",
      "Epoch: 240, Time Spent: 14520.00s, Accuracy: 92.67%\n",
      "Epoch: 241, Time Spent: 14579.28s, Accuracy: 92.68%\n",
      "Epoch: 242, Time Spent: 14637.58s, Accuracy: 92.66%\n",
      "Epoch: 243, Time Spent: 14696.34s, Accuracy: 92.67%\n",
      "Epoch: 244, Time Spent: 14755.09s, Accuracy: 92.68%\n",
      "Epoch: 245, Time Spent: 14813.28s, Accuracy: 92.71%\n",
      "Epoch: 246, Time Spent: 14871.63s, Accuracy: 92.71%\n",
      "Epoch: 247, Time Spent: 14930.38s, Accuracy: 92.72%\n",
      "Epoch: 248, Time Spent: 14989.15s, Accuracy: 92.73%\n",
      "Epoch: 249, Time Spent: 15047.16s, Accuracy: 92.74%\n",
      "Epoch: 250, Time Spent: 15105.25s, Accuracy: 92.74%\n",
      "Epoch: 251, Time Spent: 15164.12s, Accuracy: 92.77%\n",
      "Epoch: 252, Time Spent: 15222.03s, Accuracy: 92.78%\n",
      "Epoch: 253, Time Spent: 15281.04s, Accuracy: 92.80%\n",
      "Epoch: 254, Time Spent: 15339.82s, Accuracy: 92.83%\n",
      "Epoch: 255, Time Spent: 15397.95s, Accuracy: 92.84%\n",
      "Epoch: 256, Time Spent: 15457.04s, Accuracy: 92.86%\n",
      "Epoch: 257, Time Spent: 15515.67s, Accuracy: 92.90%\n",
      "Epoch: 258, Time Spent: 15573.38s, Accuracy: 92.91%\n",
      "Epoch: 259, Time Spent: 15631.99s, Accuracy: 92.92%\n",
      "Epoch: 260, Time Spent: 15690.80s, Accuracy: 92.92%\n",
      "Epoch: 261, Time Spent: 15750.38s, Accuracy: 92.92%\n",
      "Epoch: 262, Time Spent: 15810.10s, Accuracy: 92.91%\n",
      "Epoch: 263, Time Spent: 15868.69s, Accuracy: 92.93%\n",
      "Epoch: 264, Time Spent: 15927.98s, Accuracy: 92.94%\n",
      "Epoch: 265, Time Spent: 15988.79s, Accuracy: 92.93%\n",
      "Epoch: 266, Time Spent: 16049.34s, Accuracy: 92.95%\n",
      "Epoch: 267, Time Spent: 16110.21s, Accuracy: 92.96%\n",
      "Epoch: 268, Time Spent: 16171.40s, Accuracy: 93.00%\n",
      "Epoch: 269, Time Spent: 16232.55s, Accuracy: 93.01%\n",
      "Epoch: 270, Time Spent: 16292.94s, Accuracy: 93.01%\n",
      "Epoch: 271, Time Spent: 16353.49s, Accuracy: 93.01%\n",
      "Epoch: 272, Time Spent: 16414.49s, Accuracy: 93.03%\n",
      "Epoch: 273, Time Spent: 16474.97s, Accuracy: 93.04%\n",
      "Epoch: 274, Time Spent: 16535.45s, Accuracy: 93.05%\n",
      "Epoch: 275, Time Spent: 16596.68s, Accuracy: 93.05%\n",
      "Epoch: 276, Time Spent: 16657.23s, Accuracy: 93.06%\n",
      "Epoch: 277, Time Spent: 16717.36s, Accuracy: 93.05%\n",
      "Epoch: 278, Time Spent: 16777.16s, Accuracy: 93.09%\n",
      "Epoch: 279, Time Spent: 16837.59s, Accuracy: 93.10%\n",
      "Epoch: 280, Time Spent: 16897.51s, Accuracy: 93.12%\n",
      "Epoch: 281, Time Spent: 16958.72s, Accuracy: 93.16%\n",
      "Epoch: 282, Time Spent: 17018.97s, Accuracy: 93.17%\n",
      "Epoch: 283, Time Spent: 17081.58s, Accuracy: 93.18%\n",
      "Epoch: 284, Time Spent: 17142.29s, Accuracy: 93.20%\n",
      "Epoch: 285, Time Spent: 17202.91s, Accuracy: 93.20%\n",
      "Epoch: 286, Time Spent: 17264.96s, Accuracy: 93.22%\n",
      "Epoch: 287, Time Spent: 17325.88s, Accuracy: 93.24%\n",
      "Epoch: 288, Time Spent: 17386.34s, Accuracy: 93.23%\n",
      "Epoch: 289, Time Spent: 17446.97s, Accuracy: 93.23%\n",
      "Epoch: 290, Time Spent: 17507.27s, Accuracy: 93.26%\n",
      "Epoch: 291, Time Spent: 17568.88s, Accuracy: 93.27%\n",
      "Epoch: 292, Time Spent: 17630.13s, Accuracy: 93.26%\n",
      "Epoch: 293, Time Spent: 17692.06s, Accuracy: 93.26%\n",
      "Epoch: 294, Time Spent: 17753.45s, Accuracy: 93.26%\n",
      "Epoch: 295, Time Spent: 17815.45s, Accuracy: 93.25%\n",
      "Epoch: 296, Time Spent: 17878.40s, Accuracy: 93.26%\n",
      "Epoch: 297, Time Spent: 17941.45s, Accuracy: 93.26%\n",
      "Epoch: 298, Time Spent: 18003.27s, Accuracy: 93.27%\n",
      "Epoch: 299, Time Spent: 18065.57s, Accuracy: 93.27%\n",
      "Epoch: 300, Time Spent: 18127.19s, Accuracy: 93.28%\n"
     ]
    }
   ],
   "source": [
    "mlp2_sig = MLP_2_sigmoid(sizes=[784,128,128,10])\n",
    "mlp2_sig.train(x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cPnUX_QFpY78"
   },
   "outputs": [],
   "source": [
    "class MLP_2_tanh():\n",
    "\n",
    "# initialization\n",
    "  def __init__(self, sizes, epochs=100, l_rate=0.001):\n",
    "      self.sizes = sizes\n",
    "      self.epochs = epochs\n",
    "      self.l_rate = l_rate\n",
    "      self.params = self.initialization()\n",
    "\n",
    "  def softmax(self, x, derivative=False):\n",
    "          exps = np.exp(x - x.max())\n",
    "          if derivative:\n",
    "              return exps / np.sum(exps, axis=0) * (1 - exps / np.sum(exps, axis=0))\n",
    "          return exps / np.sum(exps, axis=0)\n",
    "\n",
    "  def sigmoid(self, x, derivative=False):\n",
    "          if derivative:\n",
    "              return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
    "          return 1/(1 + np.exp(-x))\n",
    "\n",
    "  def ReLU(self, x, derivative = False):\n",
    "        if derivative:\n",
    "          y = x\n",
    "          y[y <= 0] = 0\n",
    "          y[y > 0] = 1\n",
    "          return y\n",
    "        x[x <= 0] = 0\n",
    "        return x\n",
    "  def tanh(self, x, derivative = False):\n",
    "        t=(np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))\n",
    "        dt=1-t**2\n",
    "        if derivative:\n",
    "          return dt\n",
    "        return t\n",
    "\n",
    "\n",
    "  # with one hidden layer\n",
    "  def initialization(self):\n",
    "          # number of nodes in each layer\n",
    "        input_layer=self.sizes[0]\n",
    "        hidden_1=self.sizes[1]\n",
    "        hidden_2=self.sizes[2]\n",
    "        output_layer=self.sizes[3]\n",
    "\n",
    "        params = {\n",
    "            'W0':np.random.randn(hidden_1, input_layer) * np.sqrt(1. / hidden_1),\n",
    "            'W1':np.random.randn(hidden_2, hidden_1) * np.sqrt(1. / hidden_2),\n",
    "            'W2':np.random.randn(output_layer, hidden_2) * np.sqrt(1. / output_layer)\n",
    "        }\n",
    "\n",
    "        return params\n",
    "\n",
    "\n",
    "  def forward(self, x_train):\n",
    "        params = self.params\n",
    "        params['A0'] = x_train\n",
    "        # from input layer to hidden layer1\n",
    "        params['A1']=np.dot(params['W0'], params['A0'])\n",
    "        params['S1'] =self.tanh(params['A1'])\n",
    "\n",
    "        # hidden layer1 to hidden layer2\n",
    "        params['A2'] = np.dot(params[\"W1\"], params['S1'])\n",
    "        params['S2'] = self.tanh(params['A2'])\n",
    "\n",
    "        # hidden layer 2 to output layer\n",
    "        params['A3'] = np.dot(params[\"W2\"], params['S2'])\n",
    "        params['S3'] = self.softmax(params['A3'])\n",
    "\n",
    "        return params['S3']\n",
    "\n",
    "  def backward(self, y_train, output):\n",
    "        params = self.params\n",
    "        changes_to_w = {}\n",
    "\n",
    "        # Calculate W3 update\n",
    "        error = 2 * (output - y_train) / output.shape[0] * self.softmax(params['A3'], derivative=True)\n",
    "        changes_to_w['W2'] = np.outer(error, params['S2'])\n",
    "\n",
    "        # Calculate W1 update\n",
    "        error = np.dot(params['W2'].T, error) * self.tanh(params['A2'],derivative=True)\n",
    "        changes_to_w['W1'] = np.outer(error, params['S1'])\n",
    "\n",
    "        # Calculate W0 update\n",
    "        error = np.dot(params['W1'].T, error) * self.tanh(params['A1'],derivative=True)\n",
    "        changes_to_w['W0'] = np.outer(error, params['A0'])\n",
    "\n",
    "        return changes_to_w\n",
    "\n",
    "  def update_network_parameters(self, changes_to_w):        \n",
    "          for key, value in changes_to_w.items():\n",
    "              self.params[key] -= self.l_rate * value\n",
    "\n",
    "  def train(self, x_train, y_train, x_val, y_val):\n",
    "          start_time = time.time()\n",
    "          for iteration in range(self.epochs):\n",
    "              for x,y in zip(x_train, y_train):\n",
    "                  output = self.forward(x)\n",
    "                  changes_to_w = self.backward(y, output)\n",
    "                  self.update_network_parameters(changes_to_w)\n",
    "              \n",
    "              accuracy = self.evaluate_acc(x_val, y_val)\n",
    "              print('Epoch: {0}, Time Spent: {1:.2f}s, Accuracy: {2:.2f}%'.format(\n",
    "                  iteration+1, time.time() - start_time, accuracy * 100\n",
    "              ))\n",
    "  def evaluate_acc(self, x_val, y_val):\n",
    "          predictions = []\n",
    "\n",
    "          for x, y in zip(x_val, y_val):\n",
    "              output = self.forward(x)\n",
    "              pred = np.argmax(output)\n",
    "              predictions.append(pred == np.argmax(y))\n",
    "          return np.mean(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xhxep1RPEBB2",
    "outputId": "26ad40e2-0e0c-40b9-8641-cf2fa9ed9180"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Time Spent: 55.17s, Accuracy: 83.29%\n",
      "Epoch: 2, Time Spent: 110.37s, Accuracy: 87.27%\n",
      "Epoch: 3, Time Spent: 165.68s, Accuracy: 88.49%\n",
      "Epoch: 4, Time Spent: 221.09s, Accuracy: 89.38%\n",
      "Epoch: 5, Time Spent: 276.37s, Accuracy: 90.07%\n",
      "Epoch: 6, Time Spent: 331.61s, Accuracy: 90.67%\n",
      "Epoch: 7, Time Spent: 386.76s, Accuracy: 91.07%\n",
      "Epoch: 8, Time Spent: 441.79s, Accuracy: 91.33%\n",
      "Epoch: 9, Time Spent: 496.89s, Accuracy: 91.58%\n",
      "Epoch: 10, Time Spent: 551.88s, Accuracy: 91.76%\n",
      "Epoch: 11, Time Spent: 607.02s, Accuracy: 91.94%\n",
      "Epoch: 12, Time Spent: 661.96s, Accuracy: 92.08%\n",
      "Epoch: 13, Time Spent: 716.87s, Accuracy: 92.32%\n",
      "Epoch: 14, Time Spent: 771.79s, Accuracy: 92.50%\n",
      "Epoch: 15, Time Spent: 826.98s, Accuracy: 92.62%\n",
      "Epoch: 16, Time Spent: 882.03s, Accuracy: 92.78%\n",
      "Epoch: 17, Time Spent: 937.03s, Accuracy: 92.86%\n",
      "Epoch: 18, Time Spent: 992.16s, Accuracy: 92.97%\n",
      "Epoch: 19, Time Spent: 1047.29s, Accuracy: 93.11%\n",
      "Epoch: 20, Time Spent: 1102.28s, Accuracy: 93.19%\n",
      "Epoch: 21, Time Spent: 1157.28s, Accuracy: 93.23%\n",
      "Epoch: 22, Time Spent: 1212.55s, Accuracy: 93.38%\n",
      "Epoch: 23, Time Spent: 1267.61s, Accuracy: 93.47%\n",
      "Epoch: 24, Time Spent: 1322.73s, Accuracy: 93.57%\n",
      "Epoch: 25, Time Spent: 1377.43s, Accuracy: 93.67%\n",
      "Epoch: 26, Time Spent: 1432.09s, Accuracy: 93.75%\n",
      "Epoch: 27, Time Spent: 1486.58s, Accuracy: 93.83%\n",
      "Epoch: 28, Time Spent: 1540.95s, Accuracy: 93.88%\n",
      "Epoch: 29, Time Spent: 1595.29s, Accuracy: 94.01%\n",
      "Epoch: 30, Time Spent: 1649.54s, Accuracy: 94.15%\n",
      "Epoch: 31, Time Spent: 1703.82s, Accuracy: 94.22%\n",
      "Epoch: 32, Time Spent: 1758.03s, Accuracy: 94.29%\n",
      "Epoch: 33, Time Spent: 1812.38s, Accuracy: 94.29%\n",
      "Epoch: 34, Time Spent: 1866.63s, Accuracy: 94.32%\n",
      "Epoch: 35, Time Spent: 1921.03s, Accuracy: 94.40%\n",
      "Epoch: 36, Time Spent: 1975.31s, Accuracy: 94.46%\n",
      "Epoch: 37, Time Spent: 2029.59s, Accuracy: 94.56%\n",
      "Epoch: 38, Time Spent: 2084.00s, Accuracy: 94.59%\n",
      "Epoch: 39, Time Spent: 2138.38s, Accuracy: 94.68%\n",
      "Epoch: 40, Time Spent: 2192.78s, Accuracy: 94.73%\n",
      "Epoch: 41, Time Spent: 2247.26s, Accuracy: 94.78%\n",
      "Epoch: 42, Time Spent: 2301.60s, Accuracy: 94.86%\n",
      "Epoch: 43, Time Spent: 2355.98s, Accuracy: 94.92%\n",
      "Epoch: 44, Time Spent: 2410.25s, Accuracy: 94.96%\n",
      "Epoch: 45, Time Spent: 2464.70s, Accuracy: 95.01%\n",
      "Epoch: 46, Time Spent: 2519.08s, Accuracy: 95.03%\n",
      "Epoch: 47, Time Spent: 2573.47s, Accuracy: 95.05%\n",
      "Epoch: 48, Time Spent: 2627.78s, Accuracy: 95.09%\n",
      "Epoch: 49, Time Spent: 2682.04s, Accuracy: 95.11%\n",
      "Epoch: 50, Time Spent: 2736.50s, Accuracy: 95.18%\n",
      "Epoch: 51, Time Spent: 2791.00s, Accuracy: 95.24%\n",
      "Epoch: 52, Time Spent: 2845.39s, Accuracy: 95.29%\n",
      "Epoch: 53, Time Spent: 2899.79s, Accuracy: 95.34%\n",
      "Epoch: 54, Time Spent: 2954.13s, Accuracy: 95.35%\n",
      "Epoch: 55, Time Spent: 3008.53s, Accuracy: 95.40%\n",
      "Epoch: 56, Time Spent: 3063.00s, Accuracy: 95.42%\n",
      "Epoch: 57, Time Spent: 3117.30s, Accuracy: 95.44%\n",
      "Epoch: 58, Time Spent: 3171.62s, Accuracy: 95.45%\n",
      "Epoch: 59, Time Spent: 3225.94s, Accuracy: 95.45%\n",
      "Epoch: 60, Time Spent: 3280.48s, Accuracy: 95.46%\n",
      "Epoch: 61, Time Spent: 3334.95s, Accuracy: 95.53%\n",
      "Epoch: 62, Time Spent: 3389.24s, Accuracy: 95.57%\n",
      "Epoch: 63, Time Spent: 3443.68s, Accuracy: 95.61%\n",
      "Epoch: 64, Time Spent: 3498.00s, Accuracy: 95.59%\n",
      "Epoch: 65, Time Spent: 3552.37s, Accuracy: 95.60%\n",
      "Epoch: 66, Time Spent: 3606.65s, Accuracy: 95.61%\n",
      "Epoch: 67, Time Spent: 3661.02s, Accuracy: 95.65%\n",
      "Epoch: 68, Time Spent: 3715.28s, Accuracy: 95.67%\n",
      "Epoch: 69, Time Spent: 3769.57s, Accuracy: 95.67%\n",
      "Epoch: 70, Time Spent: 3823.92s, Accuracy: 95.67%\n",
      "Epoch: 71, Time Spent: 3878.26s, Accuracy: 95.70%\n",
      "Epoch: 72, Time Spent: 3932.56s, Accuracy: 95.73%\n",
      "Epoch: 73, Time Spent: 3986.77s, Accuracy: 95.79%\n",
      "Epoch: 74, Time Spent: 4040.91s, Accuracy: 95.81%\n",
      "Epoch: 75, Time Spent: 4095.11s, Accuracy: 95.86%\n",
      "Epoch: 76, Time Spent: 4149.50s, Accuracy: 95.87%\n",
      "Epoch: 77, Time Spent: 4203.83s, Accuracy: 95.87%\n",
      "Epoch: 78, Time Spent: 4258.20s, Accuracy: 95.90%\n",
      "Epoch: 79, Time Spent: 4312.49s, Accuracy: 95.92%\n",
      "Epoch: 80, Time Spent: 4366.82s, Accuracy: 95.94%\n",
      "Epoch: 81, Time Spent: 4421.16s, Accuracy: 95.95%\n",
      "Epoch: 82, Time Spent: 4475.77s, Accuracy: 95.94%\n",
      "Epoch: 83, Time Spent: 4530.71s, Accuracy: 95.94%\n",
      "Epoch: 84, Time Spent: 4585.08s, Accuracy: 95.95%\n",
      "Epoch: 85, Time Spent: 4639.60s, Accuracy: 95.98%\n",
      "Epoch: 86, Time Spent: 4694.19s, Accuracy: 95.99%\n",
      "Epoch: 87, Time Spent: 4748.71s, Accuracy: 96.00%\n",
      "Epoch: 88, Time Spent: 4803.29s, Accuracy: 96.01%\n",
      "Epoch: 90, Time Spent: 4911.89s, Accuracy: 96.06%\n",
      "Epoch: 91, Time Spent: 4966.27s, Accuracy: 96.05%\n",
      "Epoch: 92, Time Spent: 5020.61s, Accuracy: 96.08%\n",
      "Epoch: 93, Time Spent: 5075.03s, Accuracy: 96.11%\n",
      "Epoch: 94, Time Spent: 5129.45s, Accuracy: 96.13%\n",
      "Epoch: 95, Time Spent: 5184.14s, Accuracy: 96.14%\n",
      "Epoch: 96, Time Spent: 5238.67s, Accuracy: 96.21%\n",
      "Epoch: 97, Time Spent: 5293.10s, Accuracy: 96.22%\n",
      "Epoch: 98, Time Spent: 5347.52s, Accuracy: 96.23%\n",
      "Epoch: 99, Time Spent: 5401.79s, Accuracy: 96.25%\n",
      "Epoch: 100, Time Spent: 5456.22s, Accuracy: 96.27%\n"
     ]
    }
   ],
   "source": [
    "mlp2_tanh = MLP_2_tanh(sizes=[784,128,128,10])\n",
    "mlp2_tanh.train(x_train,y_train,x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjfCinL2rkLf"
   },
   "source": [
    "# L2 regularization with ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H9LaNrQG8kRW"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZF2Z3T4Zriqb"
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "(train_images, train_labels),(test_images, test_labels) = keras.datasets.fashion_mnist.load_data()\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "#validation_images = train_images[:5000]\n",
    "#validation_labels = train_labels[:5000]\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    keras.layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=0.001)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels, epochs=500)\n",
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bB18pNmxKVj5"
   },
   "source": [
    "# Ploting performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zuZxEq75Kjt0"
   },
   "source": [
    "## 2 hidden layer with tanh as activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349.0
    },
    "id": "Q2LDGlKYJ9UD",
    "outputId": "39e71397-7dda-4861-ceac-ceb79dd5c66b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.833, 0.873, 0.885, 0.894, 0.901, 0.907, 0.911, 0.913, 0.916, 0.918, 0.919, 0.921, 0.923, 0.925, 0.926, 0.928, 0.929, 0.93, 0.931, 0.932, 0.932, 0.934, 0.935, 0.936, 0.937, 0.938, 0.938, 0.939, 0.94, 0.942, 0.942, 0.943, 0.943, 0.943, 0.944, 0.945, 0.946, 0.946, 0.947, 0.947, 0.948, 0.949, 0.949, 0.95, 0.95, 0.95, 0.951, 0.951, 0.951, 0.952, 0.952, 0.953, 0.953, 0.953, 0.954, 0.954, 0.954, 0.955, 0.955, 0.955, 0.955, 0.956, 0.956, 0.956, 0.956, 0.956, 0.957, 0.957, 0.957, 0.957, 0.957, 0.957, 0.958, 0.958, 0.959, 0.959, 0.959, 0.959, 0.959, 0.959, 0.96, 0.959, 0.959, 0.96, 0.96, 0.96, 0.96, 0.96, 0.961, 0.961, 0.961, 0.961, 0.961, 0.961, 0.962, 0.962, 0.962, 0.963, 0.963]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import xlwt\n",
    "import os\n",
    "\n",
    "with open('h2_tanh.txt','r+') as fd:\n",
    "  e = list(range(1,100))\n",
    "  p = []\n",
    "  #read all accuracy from the performance report\n",
    "  for text in fd.readlines():\n",
    "    y=text.split(':')[3].strip(\"\\n\").strip('%').strip()\n",
    "    p.append(y.split(\"\\n\"))\n",
    "\n",
    "  p = list(np.concatenate(p).flat)\n",
    "  p = [round(float(i)/100,3) for i in p]\n",
    "  print(p)\n",
    "  print(e)\n",
    "\n",
    "fd.close()\n",
    "\n",
    "plt.plot(e, p, color='green',  linewidth = 2)\n",
    "  \n",
    "# setting x and y axis range\n",
    "plt.ylim(0,1)\n",
    "plt.xlim(1,100)\n",
    "  \n",
    "# naming the x axis\n",
    "plt.xlabel('Iterations')\n",
    "# naming the y axis\n",
    "plt.ylabel('Accuracy')\n",
    "  \n",
    "# giving a title to my graph\n",
    "plt.title('Two hidden layer with tanh performance')\n",
    "  \n",
    "# function to show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMZYXdbZLSxY"
   },
   "source": [
    "## 2 hidden layer with sigmoid as activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349.0
    },
    "id": "iRRcb0MtLYJR",
    "outputId": "97ca7eb7-eaac-453e-8376-966d4ca98862"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.232, 0.412, 0.493, 0.524, 0.556, 0.584, 0.6, 0.61, 0.623, 0.636, 0.647, 0.652, 0.655, 0.657, 0.657, 0.656, 0.657, 0.658, 0.66, 0.664, 0.669, 0.677, 0.685, 0.695, 0.704, 0.714, 0.721, 0.729, 0.735, 0.743, 0.75, 0.755, 0.758, 0.763, 0.765, 0.768, 0.77, 0.772, 0.774, 0.776, 0.778, 0.779, 0.782, 0.786, 0.791, 0.795, 0.798, 0.803, 0.805, 0.807, 0.807, 0.809, 0.81, 0.81, 0.81, 0.812, 0.812, 0.812, 0.812, 0.812, 0.812, 0.814, 0.813, 0.813, 0.814, 0.814, 0.815, 0.815, 0.816, 0.816, 0.816, 0.817, 0.817, 0.817, 0.818, 0.818, 0.818, 0.818, 0.818, 0.819, 0.819, 0.819, 0.82, 0.821, 0.824, 0.828, 0.833, 0.841, 0.847, 0.853, 0.86, 0.866, 0.871, 0.874, 0.877, 0.879, 0.88, 0.881, 0.883, 0.884]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('sig.txt','r+') as fd:\n",
    "  e = list(range(1,101))\n",
    "  p = []\n",
    "  #read all accuracy from the performance report\n",
    "  for text in fd.readlines():\n",
    "    y=text.split(':')[3].strip(\"\\n\").strip('%').strip()\n",
    "    p.append(y.split(\"\\n\"))\n",
    "\n",
    "  p = list(np.concatenate(p).flat)\n",
    "  p = [round(float(i)/100,3) for i in p]\n",
    "  print(p)\n",
    "  print(e)\n",
    "\n",
    "fd.close()\n",
    "\n",
    "plt.plot(e, p, color='green',  linewidth = 2)\n",
    "  \n",
    "# setting x and y axis range\n",
    "plt.ylim(0,1)\n",
    "plt.xlim(1,100)\n",
    "  \n",
    "# naming the x axis\n",
    "plt.xlabel('Iterations')\n",
    "# naming the y axis\n",
    "plt.ylabel('Accuracy')\n",
    "  \n",
    "# giving a title to my graph\n",
    "plt.title('Two hidden layer with sigmoid performance')\n",
    "  \n",
    "# function to show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BeNB9GdYMdDk"
   },
   "source": [
    "## 2 hidden layer with RELU as activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349.0
    },
    "id": "z-gYmXtAMhoP",
    "outputId": "848dd694-e228-43ff-c267-1c17296b0e9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75, 0.851, 0.882, 0.894, 0.901, 0.907, 0.911, 0.913, 0.916, 0.919, 0.922, 0.923, 0.926, 0.928, 0.93, 0.931, 0.932, 0.934, 0.935, 0.935, 0.937, 0.937, 0.938, 0.939, 0.939, 0.94, 0.941, 0.941, 0.942, 0.942, 0.943, 0.943, 0.944, 0.944, 0.945, 0.946, 0.946, 0.946, 0.946, 0.947, 0.948, 0.948, 0.948, 0.948, 0.948, 0.949, 0.949, 0.949, 0.949, 0.95, 0.95, 0.95, 0.95, 0.952, 0.952, 0.952, 0.952, 0.952, 0.952, 0.952, 0.952, 0.953, 0.953, 0.953, 0.953, 0.953, 0.953, 0.953, 0.953, 0.953, 0.954, 0.954, 0.954, 0.955, 0.955, 0.955, 0.955, 0.956, 0.956, 0.956, 0.956, 0.956, 0.956, 0.956, 0.956, 0.957, 0.957, 0.957, 0.957, 0.957, 0.956, 0.956, 0.956, 0.956, 0.956, 0.956, 0.956, 0.956, 0.957, 0.957]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": [],
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('h2_relu.txt','r+') as fd:\n",
    "  e = list(range(1,101))\n",
    "  p = []\n",
    "  #read all accuracy from the performance report\n",
    "  for text in fd.readlines():\n",
    "    y=text.split(':')[3].strip(\"\\n\").strip('%').strip()\n",
    "    p.append(y.split(\"\\n\"))\n",
    "\n",
    "  p = list(np.concatenate(p).flat)\n",
    "  p = [round(float(i)/100,3) for i in p]\n",
    "  print(p)\n",
    "  print(e)\n",
    "\n",
    "fd.close()\n",
    "\n",
    "plt.plot(e, p, color='green',  linewidth = 2)\n",
    "  \n",
    "# setting x and y axis range\n",
    "plt.ylim(0,1)\n",
    "plt.xlim(1,100)\n",
    "  \n",
    "# naming the x axis\n",
    "plt.xlabel('Iterations')\n",
    "# naming the y axis\n",
    "plt.ylabel('Accuracy')\n",
    "  \n",
    "# giving a title to my graph\n",
    "plt.title('Two hidden layer with RELU performance')\n",
    "  \n",
    "# function to show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "COMP551P3_0&2 hidden.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
