{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tQuiyC7ve96S"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.4.1\n",
    "!pip install gpustat\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qCZbG75IbgTV"
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train, x_test = x_train[..., np.newaxis]/255.0, x_test[..., np.newaxis]/255.0\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# reshape\n",
    "x_train = np.reshape(x_train, (60000, 784))\n",
    "x_test = np.reshape(x_test, (10000, 784))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VmwNnGH5fT4k"
   },
   "outputs": [],
   "source": [
    "class MLP_2():\n",
    "\n",
    "  # initialization\n",
    "  def __init__(self, sizes, epochs=100, l_rate=0.001):\n",
    "      self.sizes = sizes\n",
    "      self.epochs = epochs\n",
    "      self.l_rate = l_rate\n",
    "      self.params = self.initialization()\n",
    "\n",
    "  def softmax(self, x, derivative=False):\n",
    "          exps = np.exp(x - x.max())\n",
    "          if derivative:\n",
    "              return exps / np.sum(exps, axis=0) * (1 - exps / np.sum(exps, axis=0))\n",
    "          return exps / np.sum(exps, axis=0)\n",
    "\n",
    "  def sigmoid(self, x, derivative=False):\n",
    "          if derivative:\n",
    "              return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
    "          return 1/(1 + np.exp(-x))\n",
    "\n",
    "  def ReLU(self, x, derivative = False):\n",
    "        if derivative:\n",
    "          y = x\n",
    "          y[y <= 0] = 0\n",
    "          y[y > 0] = 1\n",
    "          return y\n",
    "        x[x <= 0] = 0\n",
    "        return x\n",
    "\n",
    "\n",
    "  # with one hidden layer\n",
    "  def initialization(self):\n",
    "          # number of nodes in each layer\n",
    "        input_layer=self.sizes[0]\n",
    "        hidden_1=self.sizes[1]\n",
    "        hidden_2=self.sizes[2]\n",
    "        output_layer=self.sizes[3]\n",
    "\n",
    "        params = {\n",
    "            'W0':np.random.randn(hidden_1, input_layer) * np.sqrt(1. / hidden_1),\n",
    "            'W1':np.random.randn(hidden_2, hidden_1) * np.sqrt(1. / hidden_2),\n",
    "            'W2':np.random.randn(output_layer, hidden_2) * np.sqrt(1. / output_layer)\n",
    "        }\n",
    "\n",
    "        return params\n",
    "\n",
    "\n",
    "  def forward(self, x_train):\n",
    "        params = self.params\n",
    "        params['A0'] = x_train\n",
    "        # from input layer to hidden layer1\n",
    "        params['A1']=np.dot(params['W0'], params['A0'])\n",
    "        params['S1'] =self.ReLU(params['A1'])\n",
    "\n",
    "        # hidden layer1 to hidden layer2\n",
    "        params['A2'] = np.dot(params[\"W1\"], params['S1'])\n",
    "        params['S2'] = self.ReLU(params['A2'])\n",
    "\n",
    "        # hidden layer 2 to output layer\n",
    "        params['A3'] = np.dot(params[\"W2\"], params['S2'])\n",
    "        params['S3'] = self.softmax(params['A3'])\n",
    "\n",
    "        return params['S3']\n",
    "\n",
    "  def backward(self, y_train, output):\n",
    "        params = self.params\n",
    "        changes_to_w = {}\n",
    "\n",
    "        # Calculate W3 update\n",
    "        error = 2 * (output - y_train) / output.shape[0] * self.softmax(params['A3'], derivative=True)\n",
    "        changes_to_w['W2'] = np.outer(error, params['S2'])\n",
    "\n",
    "        # Calculate W1 update\n",
    "        error = np.dot(params['W2'].T, error) * self.ReLU(params['A2'],derivative=True)\n",
    "        changes_to_w['W1'] = np.outer(error, params['S1'])\n",
    "\n",
    "        # Calculate W0 update\n",
    "        error = np.dot(params['W1'].T, error) * self.ReLU(params['A1'],derivative=True)\n",
    "        changes_to_w['W0'] = np.outer(error, params['A0'])\n",
    "\n",
    "        return changes_to_w\n",
    "\n",
    "  def update_network_parameters(self, changes_to_w):        \n",
    "          for key, value in changes_to_w.items():\n",
    "              self.params[key] -= self.l_rate * value\n",
    "\n",
    "  def train(self, x_train, y_train, x_val, y_val):\n",
    "          start_time = time.time()\n",
    "          for iteration in range(self.epochs):\n",
    "              for x,y in zip(x_train, y_train):\n",
    "                  output = self.forward(x)\n",
    "                  changes_to_w = self.backward(y, output)\n",
    "                  self.update_network_parameters(changes_to_w)\n",
    "              \n",
    "              accuracy = self.evaluate_acc(x_val, y_val)\n",
    "              print('Epoch: {0}, Time Spent: {1:.2f}s, Accuracy: {2:.2f}%'.format(\n",
    "                  iteration+1, time.time() - start_time, accuracy * 100\n",
    "              ))\n",
    "  def evaluate_acc(self, x_val, y_val):\n",
    "          predictions = []\n",
    "\n",
    "          for x, y in zip(x_val, y_val):\n",
    "              output = self.forward(x)\n",
    "              pred = np.argmax(output)\n",
    "              predictions.append(pred == np.argmax(y))\n",
    "              \n",
    "          return np.mean(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHv4Bt6OfhHR"
   },
   "outputs": [],
   "source": [
    "mlp2_unormalized = MLP_2(sizes=[784,128,128,10])\n",
    "mlp2_unormalized.train(x_train,y_train,x_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "COMP551P3_RELU_2_Unormalized.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
